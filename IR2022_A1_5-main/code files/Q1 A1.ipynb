{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92e1957",
   "metadata": {},
   "source": [
    "# IMPORTING NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4db834f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1dbd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb96c99",
   "metadata": {},
   "source": [
    "# INVERTED INDEX CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "565bf508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted index dictionary creation\n",
    "index = {}\n",
    "# document id to document name conversion\n",
    "DOCINFO = {} #contains the information about the document\n",
    "power_set = [] #this is going to be the power set which is the universe U\n",
    "one,two = 1,2 #these are the variables which we use for updating the number of comparisons by 1 and 2 respectively\n",
    "wind = \"\\\\\" #for windows, we use this \n",
    "ubuntu = \"/\" #for ubuntu  we use this\n",
    "active = wind #active means we are using which either windows or ubuntu currently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd2218",
   "metadata": {},
   "source": [
    "# OR QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1aac8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XORY(x, y): #this returns the number of comparisons and the number of retrieved documents when we perform or operation\n",
    "    x, y = sorted(x), sorted(y) #we sort both the x and y before doing computations on them, this way we can do it fast\n",
    "    _OR = [] #this is going to be the array where we will store the words\n",
    "    comp = 0 #number of cmparisons we will store here.\n",
    "    i, j = 0, 0 #initiase the iterators i and j to 0 i iterates x and j iterates y\n",
    "    while i<len(x) and j<len(y):\n",
    "        if x[i]==y[j]: #first comparison , if this is false, we have to do one more comparison\n",
    "            _OR.append(y[j]) #if you have found the match, in that case, just simply, append the word in the or array\n",
    "            j += 1 #i will move one step ahead\n",
    "            i += 1 #j will move one step ahead\n",
    "            comp +=one #the number of comparisons we did in this case is simply 1 as we compared x[i] with y[j]\n",
    "        else: #if there is not a match, in that case, if block is not executed and we have wasted one comparison there.\n",
    "            comp += two #hence, we increase the comparison count by two.\n",
    "            if x[i]<y[j]: #so, if x[i] is less than y[j] this means, we have found x[i] so we will append x[i]\n",
    "                _OR.append(x[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                _OR.append(y[j]) #likewise we will process y[j] and and append y[j] in the array\n",
    "                j += 1\n",
    "    while i<len(x): #for all theh remaining array lengths, we will append the array like this\n",
    "        _OR.append(x[i])\n",
    "        i += 1 #increment i to move forward\n",
    "    while j<len(y):\n",
    "        _OR.append(y[j])\n",
    "        j += 1\n",
    "    return _OR, comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cf205",
   "metadata": {},
   "source": [
    "# AND QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f1b997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def XANDY(x, y):\n",
    "    x, y = sorted(x), sorted(y)\n",
    "    _AND = []\n",
    "    comp = 0\n",
    "    i, j = 0, 0\n",
    "    while i<len(x) and j<len(y):\n",
    "        if x[i] == y[j]:\n",
    "            _AND.append(y[j])\n",
    "            j += 1\n",
    "            i += 1\n",
    "            comp += one\n",
    "        else:\n",
    "            comp += two\n",
    "            if x[i]<y[j]:\n",
    "                i+=1\n",
    "            else:\n",
    "                j+=1\n",
    "    return _AND, comp #returning the and array and the number of comparisons we made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fd948",
   "metadata": {},
   "source": [
    "# SET DIFFERENCE METHOD IN ORDER TO FIND OR NOT & AND NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "663c6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XMINUSY(x, y):\n",
    "    x = sorted(x)\n",
    "    i, j = 0, 0\n",
    "    _AminusB = []\n",
    "    comp = 0\n",
    "    while i < len(x) and j < len(y):\n",
    "        if x[i] == y[j]:\n",
    "            comp += one\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            comp += two\n",
    "            if x[i] > y[j]:\n",
    "                _AminusB.append(y[j])\n",
    "                j += 1\n",
    "            else:\n",
    "                i += 1\n",
    "    while j < len(y):\n",
    "        _AminusB.append(y[j])\n",
    "        j += 1\n",
    "    return _AminusB, comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c80b59",
   "metadata": {},
   "source": [
    "# OR NOT QUERY USING SET DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf40d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x or not y = U-(y-x)\n",
    "def XORNOTY(x, y):\n",
    "    xbar, comp1 = XMINUSY(x,y)\n",
    "    xbarbar, comp2 = XMINUSY(xbar, power_set)\n",
    "    return xbarbar, comp1+comp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03eca3",
   "metadata": {},
   "source": [
    "# AND NOT QUERY USING SET DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8669516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X^Y'\n",
    "def XANDNOTY(x, y):\n",
    "    ans, comp = XMINUSY(y, x)\n",
    "    return ans, comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f917ca8",
   "metadata": {},
   "source": [
    "# METHOD TO GET DOCUMENT LIST CORRESPONDING TO A WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b3e7f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_list_for_word(word):\n",
    "    if word in index:\n",
    "        return index[word]\n",
    "    else:\n",
    "        var = []\n",
    "        return var\n",
    "def get_name_for_doc_id(doc_id):\n",
    "    if doc_id in DOCINFO:\n",
    "        return DOCINFO[doc_id]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b546e4",
   "metadata": {},
   "source": [
    "# EVALUATING THE CLUSTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8ffbfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalc(dls, operation=or_query):\n",
    "    lcpy = dls[:]\n",
    "    sum_list = {}\n",
    "    comparisons = 0\n",
    "    while len(lcpy) != 1:\n",
    "        sum_list = {}\n",
    "        for i in range(len(lcpy) - 1):\n",
    "            sum_list[i] = len(lcpy[i]) + len(lcpy[i + 1])\n",
    "\n",
    "        min_i = min(sum_list, key=sum_list.get)\n",
    "\n",
    "        lcpy[min_i], opr = operation(lcpy[min_i], lcpy[min_i + 1])\n",
    "        comparisons += opr\n",
    "        del lcpy[min_i + 1]\n",
    "\n",
    "    fl = lcpy[:][0]\n",
    "    return fl, comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808346cd",
   "metadata": {},
   "source": [
    "#  CREATING CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b2f487d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(qdl, ops):\n",
    "    # && >>> ||\n",
    "    opfun = {'OR': or_query, 'AND': and_query}\n",
    "    opers = ops[:]\n",
    "    dl = qdl[:]\n",
    "    comparisons = 0\n",
    "\n",
    "    if 'AND' in opers:\n",
    "        # Finding AND Clusters\n",
    "        clust = []\n",
    "        is_continued = False\n",
    "        i = 0\n",
    "        while i < len(opers):\n",
    "            if opers[i] == 'AND':\n",
    "                if not is_continued:\n",
    "                    is_continued = True\n",
    "                clust.append(dl[i])\n",
    "                del dl[i]\n",
    "                del opers[i]\n",
    "            else:\n",
    "                if is_continued:\n",
    "                    clust.append(dl[i])\n",
    "                    l, comp = evalc(clust, operation=opfun['AND'])\n",
    "                    clust = []\n",
    "                    dl[i] = l\n",
    "                    comparisons += comp\n",
    "                is_continued = False\n",
    "                i += 1\n",
    "        if is_continued:\n",
    "            clust.append(dl[-1])\n",
    "            l, comp = evalc(clust, operation=opfun['AND'])\n",
    "            clust = []\n",
    "            dl[i] = l\n",
    "            comparisons += comp\n",
    "\n",
    "    l, comp = evalc(dl, operation=opfun['OR'])\n",
    "\n",
    "    return l, comparisons + comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c01ecc",
   "metadata": {},
   "source": [
    "# PERFORM QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb736ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query_words, ops):\n",
    "    comparisons = 0\n",
    "    if len(query_words) == 1:\n",
    "        if len(ops) > 0:\n",
    "            print('Operations ignored.')\n",
    "        ids = get_doc_list_for_word(query_words[0])\n",
    "        return ids, 0, [get_name_for_doc_id(d_id) for d_id in ids]\n",
    "\n",
    "    if not (len(query_words) == len(ops) + 1):\n",
    "        raise ValueError('Size mismatch, expected len(qs) = {len_sent} and len(ops) = {len_opr}.'\n",
    "                         .format(len_sent=len(query_words), len_opr=len(ops)))\n",
    "\n",
    "    qdl = [0] * len(query_words)\n",
    "    for i in range(len(query_words)):\n",
    "        qdl[i] = get_doc_list_for_word(query_words[i])\n",
    "\n",
    "    dl = qdl[0]\n",
    "    comp = 0\n",
    "    for i in range(len(ops)):\n",
    "        if ops[i] == 'OR':\n",
    "            dl, comp = XORY(dl, qdl[i + 1])\n",
    "        elif ops[i] == 'AND':\n",
    "            dl, comp = XANDY(dl, qdl[i + 1])\n",
    "        elif ops[i] == 'OR NOT':\n",
    "            dl, comp = XORNOTY(dl, qdl[i + 1])\n",
    "        elif ops[i] == 'AND NOT':\n",
    "            dl, comp = XANDNOTY(dl, qdl[i + 1])\n",
    "\n",
    "        comparisons += comp\n",
    "\n",
    "    print(comparisons)\n",
    "\n",
    "    return dl, comparisons, [get_name_for_doc_id(x) for x in dl]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a2139",
   "metadata": {},
   "source": [
    "# UPDATING THE INDEX BASED ON FOLDER,  FILE AND FILE ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "008732eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_index(folder_name, filename, file_id):\n",
    "    alpha = \"\"\n",
    "    try:\n",
    "        alpha = open(folder_name + filename, 'r').read()\n",
    "    # except IOError:\n",
    "    #     print(\"This file has some problem in reading ->\", filename)\n",
    "    except UnicodeDecodeError:\n",
    "        alpha = str(open(folder_name + filename, 'rb').read())\n",
    "\n",
    "    ppalpha = pp(alpha)  # list form.\n",
    "\n",
    "    for t in ppalpha:\n",
    "        if t in index:\n",
    "            if index[t][-1] < file_id:\n",
    "                index[t].append(file_id)\n",
    "        else:\n",
    "            index[t] = [file_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd9c42",
   "metadata": {},
   "source": [
    "#  PREPARING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c720b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    cwd = os.getcwd()\n",
    "    filename_with_path = glob.glob(cwd + active + \"hhmf\" + active + \"*\")\n",
    "    F = [i.split(active)[-1] for i in filename_with_path]\n",
    "    # Indexing each filename.\n",
    "    i = 0\n",
    "    # Pre-Processing and updating 'index' dictionary\n",
    "    for filename in F:\n",
    "        update_index(cwd + active + \"hhmf\"  + active , filename, i)\n",
    "        DOCINFO[i] = filename\n",
    "        i += 1\n",
    "    global power_set\n",
    "    power_set = sorted(list(DOCINFO.keys()))\t# [0, 1, 2, ...., 467]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4f1e1",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f14083d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEL_STOPWORDS(qs):\n",
    "    return [w for w in qs if w not in sw]\n",
    "\n",
    "def pp(alpha):\n",
    "    alpha = alpha.lower()\n",
    "    alpha = re.sub(r'[+*/\\\\\\-?.>,<\\\"\\';:!@#$%^&()_`~]', ' ', alpha)\n",
    "    alpha = word_tokenize(alpha)\n",
    "    alpha = [word for word in alpha if word.isalpha()]\n",
    "    alpha = DEL_STOPWORDS(alpha)\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906b4b2",
   "metadata": {},
   "source": [
    "#  MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6397bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter no of queries : 1\n",
      "========== Preparing Dataset ========== [OK]\n",
      "Vocabulary : 65185 #Documents : 1133\n",
      "\n",
      "You are requested to enter your query : the lion stood thoughtfully for a moment\n",
      "Enter the operation sequence (Only 3 operations is needed) : [OR,OR,OR]\n",
      "Running query :  lion [OR stood OR thoughtfully OR] moment\n",
      "96\n",
      "Document ID :  [116, 135, 138, 218, 241, 248, 291, 295, 318, 322, 378, 418, 533, 595, 596, 597, 602, 635, 688, 689, 753, 791, 842, 977, 980, 1027, 1039]\n",
      "Document Names (10 max) :  ['bitnet.txt', 'boneles2.txt', 'booze1.fun', 'christop.int', 'collected_quotes.txt', 'computer.txt', 'deep.txt', 'devils.jok', 'dromes.txt', 'dthought.txt']\n",
      "Number of documents matched:  27\n",
      "Minimum Operation :  96\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    T = int(input('Enter no of queries : ').strip())\n",
    "    if T == 0:\n",
    "        return\n",
    "    print('========== Preparing Dataset ==========', end=' ')\n",
    "    prepare_dataset()  # index is updated.\n",
    "    print('[OK]')\n",
    "    print(\"Vocabulary :\", len(index.keys()), '#Documents :', len(power_set))\n",
    "    for i in range(T):\n",
    "        qs = pp(input('\\nYou are requested to enter your query : '))\n",
    "        if len(qs) > 0:\n",
    "            n = len(qs) - 1\n",
    "            ops = input('Enter the operation sequence (Only ' + str(n) + ' operations is needed) : ').split(\",\")\n",
    "            ops = [x.strip().upper() for x in ops]\n",
    "            print('Running query : ', end=' ')\n",
    "            for j in range(len(ops)):\n",
    "                print(qs[j], end=' ')\n",
    "                print(ops[j], end=' ')\n",
    "            print(qs[-1])\n",
    "            doc_id, minops, doc_names = perform_query(qs, ops)\n",
    "            print(\"Document ID : \", doc_id)\n",
    "            print(\"Document Names (10 max) : \", doc_names[:10])\n",
    "            print(\"Number of documents matched: \", len(doc_id))\n",
    "            print(\"Minimum Operation : \", minops)\n",
    "        else:\n",
    "            print('Nothing to process')\n",
    "if \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b21aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
